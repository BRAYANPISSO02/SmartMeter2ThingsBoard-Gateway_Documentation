\chapter{Pruebas y Resultados}

\section{Introducción}

Este capítulo presenta la metodología, procedimientos y resultados de las pruebas realizadas para validar el sistema SmartMeter2ThingsBoard-Gateway. Se cubren pruebas unitarias, de integración, funcionales, de rendimiento y de resiliencia, junto con el análisis de resultados obtenidos y su relación con los objetivos planteados.

\section{Estrategia de Pruebas}

\subsection{Niveles de Prueba}

La estrategia de pruebas se organizó en cuatro niveles:

\begin{enumerate}
    \item \textbf{Pruebas Unitarias:} Validación de componentes individuales (funciones, clases)
    \item \textbf{Pruebas de Integración:} Validación de interacción entre módulos
    \item \textbf{Pruebas Funcionales:} Validación de requisitos end-to-end
    \item \textbf{Pruebas de Rendimiento:} Validación de escalabilidad y latencias
    \item \textbf{Pruebas de Resiliencia:} Validación de recuperación ante fallos
\end{enumerate}

\subsection{Entorno de Pruebas}

\begin{table}[h]
\centering
\caption{Configuración del entorno de pruebas}
\begin{tabular}{ll}
\toprule
\textbf{Componente} & \textbf{Especificación} \\
\midrule
Sistema Operativo & Ubuntu 22.04 LTS \\
CPU & Intel Core i7-10700 (8 cores, 16 threads) \\
RAM & 32 GB DDR4 \\
Almacenamiento & SSD NVMe 512 GB \\
Red & Ethernet 1 Gbps \\
Python & 3.11.6 \\
Docker & 24.0.7 \\
ThingsBoard & 4.2.1 \\
PostgreSQL & 16.1 con TimescaleDB 2.13 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Métricas de Evaluación}

Las métricas principales evaluadas fueron:

\begin{itemize}
    \item \textbf{Funcionalidad:} Tasa de éxito de operaciones (lectura, escritura, conexión)
    \item \textbf{Rendimiento:} Latencia de lecturas, throughput de telemetría
    \item \textbf{Escalabilidad:} Número máximo de medidores concurrentes
    \item \textbf{Disponibilidad:} Tiempo de recuperación ante fallos (MTTR)
    \item \textbf{Precisión:} Exactitud de datos leídos vs. valores reales
\end{itemize}

\section{Pruebas Unitarias}

\subsection{Cobertura de Código}

Se ejecutaron pruebas unitarias con pytest y medición de cobertura con coverage.py:

\begin{verbatim}
$ pytest --cov=src --cov-report=term-missing

---------- coverage: platform linux, python 3.11.6 -----------
Name                              Stmts   Miss  Cover
-----------------------------------------------------
src/dlms/client.py                  247     12    95%
src/dlms/hdlc.py                    156      8    95%
src/dlms/cosem.py                   189     15    92%
src/orchestrator/orchestrator.py    312     18    94%
src/orchestrator/meter_manager.py   178     10    94%
src/mqtt/gateway.py                 145      7    95%
-----------------------------------------------------
TOTAL                              1227     70    94%
\end{verbatim}

\textbf{Resultado:} Cobertura del \textbf{94\%} del código, cumpliendo el objetivo de >90\%.

\subsection{Casos de Prueba Críticos}

\subsubsection{Test 1: Construcción de Trama HDLC}

\begin{verbatim}
Descripción: Verificar construcción correcta de tramas HDLC
Entrada: Address=1, Control=0x10, Information=[0x01, 0x02]
Salida Esperada: Trama válida con flags, CRC correcto
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 1 - Construcción HDLC}
\begin{tabular}{lcc}
\toprule
\textbf{Aspecto Verificado} & \textbf{Esperado} & \textbf{Resultado} \\
\midrule
Flag de inicio & 0x7E & \ding{51} \\
Flag de fin & 0x7E & \ding{51} \\
CRC-16 válido & Correcto & \ding{51} \\
Longitud de trama & 13 bytes & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Test 2: Decodificación de Valores DLMS}

\begin{verbatim}
Descripción: Verificar decodificación de tipos DLMS
Casos:
- Tipo 0x06 (long): [0x00, 0x00, 0x05, 0xDC] -> 1500
- Tipo 0x12 (unsigned): [0x00, 0xE6] -> 230
- Tipo 0x09 (string): "METER001" -> "METER001"
\end{verbatim}

\textbf{Resultado:} 100\% de casos correctos (27/27 tipos probados).

\subsubsection{Test 3: Retry con Backoff Exponencial}

\begin{verbatim}
Descripción: Verificar estrategia de reintentos
Escenario: Simular 3 fallos consecutivos seguidos de éxito
Delays esperados: 2s, 4s, 8s
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 3 - Retry con Backoff}
\begin{tabular}{cccc}
\toprule
\textbf{Intento} & \textbf{Delay Esperado} & \textbf{Delay Medido} & \textbf{Estado} \\
\midrule
1 & 2.0s & 2.03s & Falló \\
2 & 4.0s & 4.01s & Falló \\
3 & 8.0s & 8.05s & Falló \\
4 & - & - & Éxito \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Delays dentro del margen de error (<5\%), recuperación exitosa.

\section{Pruebas de Integración}

\subsection{Integración DLMS-Medidor}

\subsubsection{Test 4: Conexión y Autenticación}

\begin{verbatim}
Descripción: Establecer conexión DLMS completa
Pasos:
1. Enviar SNRM
2. Recibir UA
3. Enviar AARQ con password
4. Recibir AARE con resultado=accepted
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 4 - Conexión DLMS}
\begin{tabular}{lcc}
\toprule
\textbf{Medidor} & \textbf{Tiempo de Conexión} & \textbf{Estado} \\
\midrule
Meter\_001 (Landis+Gyr E350) & 1.24s & \ding{51} \\
Meter\_002 (Itron ACE6000) & 1.56s & \ding{51} \\
Meter\_003 (ZIV 5CTA) & 2.13s & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} 100\% de conexiones exitosas, tiempo promedio \textbf{1.64s}.

\subsubsection{Test 5: Lectura de Objetos COSEM}

\begin{verbatim}
Descripción: Leer objetos comunes de medidores
Objetos:
- 1.0.1.8.0.255: Energía activa total
- 1.0.32.7.0.255: Voltaje L1
- 1.0.31.7.0.255: Corriente L1
- 0.0.96.1.0.255: Número de serie
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 5 - Lectura de Objetos}
\begin{tabular}{lccc}
\toprule
\textbf{OBIS Code} & \textbf{Valor Leído} & \textbf{Valor Real} & \textbf{Precisión} \\
\midrule
1.0.1.8.0.255 & 15432.8 kWh & 15432.8 kWh & 100\% \\
1.0.32.7.0.255 & 230.5 V & 230.4 V & 99.96\% \\
1.0.31.7.0.255 & 12.3 A & 12.3 A & 100\% \\
0.0.96.1.0.255 & "LGE350..." & "LGE350..." & 100\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Precisión promedio \textbf{99.99\%}, todas las lecturas exitosas.

\subsection{Integración MQTT-ThingsBoard}

\subsubsection{Test 6: Publicación de Telemetría}

\begin{verbatim}
Descripción: Publicar telemetría y verificar recepción en ThingsBoard
Formato:
{
    "meter_001": [{
        "ts": 1704067200000,
        "values": {"voltage_l1": 230.5, "current_l1": 12.3}
    }]
}
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 6 - Publicación MQTT}
\begin{tabular}{lccc}
\toprule
\textbf{Métrica} & \textbf{Valor} & \textbf{Objetivo} & \textbf{Estado} \\
\midrule
Mensajes enviados & 1000 & 1000 & \ding{51} \\
Mensajes recibidos & 1000 & 1000 & \ding{51} \\
Latencia promedio & 24 ms & <100 ms & \ding{51} \\
Latencia P99 & 87 ms & <500 ms & \ding{51} \\
Pérdida de paquetes & 0\% & <0.1\% & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} \textbf{0\% de pérdida} de mensajes, latencia excelente.

\subsubsection{Test 7: Creación Automática de Dispositivos}

\begin{verbatim}
Descripción: Verificar provisioning automático de dispositivos
Escenario: Publicar telemetría de 3 dispositivos nuevos
Verificar: Creación automática en ThingsBoard con atributos correctos
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 7 - Auto-provisioning}
\begin{tabular}{lcc}
\toprule
\textbf{Dispositivo} & \textbf{Creado} & \textbf{Atributos Correctos} \\
\midrule
meter\_test\_001 & Sí & \ding{51} \\
meter\_test\_002 & Sí & \ding{51} \\
meter\_test\_003 & Sí & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} 100\% de dispositivos creados automáticamente con metadatos correctos.

\section{Pruebas Funcionales}

\subsection{Prueba End-to-End}

\subsubsection{Test 8: Flujo Completo de Telemetría}

\begin{verbatim}
Descripción: Validar flujo completo desde medidor hasta dashboard
Pasos:
1. Orquestador lee medidor DLMS
2. Transforma datos a formato ThingsBoard
3. Publica vía MQTT con QoS 1
4. ThingsBoard recibe y almacena
5. Dashboard muestra datos actualizados
\end{verbatim}

\begin{figure}[h]
\centering
\begin{tikzpicture}[node distance=1.5cm, auto, >=latex']
    \node [draw, rectangle] (read) {Lectura DLMS};
    \node [draw, rectangle, right=of read] (transform) {Transformación};
    \node [draw, rectangle, right=of transform] (mqtt) {Publicación MQTT};
    \node [draw, rectangle, below=of mqtt] (tb) {Almacenamiento TB};
    \node [draw, rectangle, left=of tb] (dash) {Visualización};
    
    \draw[->] (read) -- node {1.2s} (transform);
    \draw[->] (transform) -- node {0.02s} (mqtt);
    \draw[->] (mqtt) -- node {0.05s} (tb);
    \draw[->] (tb) -- node {0.3s} (dash);
\end{tikzpicture}
\caption{Latencias en flujo end-to-end}
\end{figure}

\begin{table}[h]
\centering
\caption{Resultados Test 8 - Flujo End-to-End}
\begin{tabular}{lcc}
\toprule
\textbf{Etapa} & \textbf{Latencia} & \textbf{Estado} \\
\midrule
Lectura DLMS & 1.2s & \ding{51} \\
Transformación & 0.02s & \ding{51} \\
Publicación MQTT & 0.05s & \ding{51} \\
Almacenamiento TB & 0.3s & \ding{51} \\
Visualización & 0.4s & \ding{51} \\
\midrule
\textbf{Total} & \textbf{1.97s} & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Latencia total \textbf{<2s}, cumple objetivo de near real-time.

\subsection{Validación de Requisitos}

\subsubsection{Test 9: Cumplimiento de Objetivos Específicos}

\begin{table}[h]
\centering
\caption{Validación de objetivos específicos}
\begin{tabular}{p{8cm}cc}
\toprule
\textbf{Objetivo Específico} & \textbf{Prueba} & \textbf{Estado} \\
\midrule
OE1: Implementar stack DLMS/COSEM & Test 4, 5 & \ding{51} \\
OE2: Gestionar múltiples medidores concurrentes & Test 10 & \ding{51} \\
OE3: Mecanismos de recuperación automática & Test 12, 13 & \ding{51} \\
OE4: Integración con ThingsBoard & Test 6, 7 & \ding{51} \\
OE5: Dashboards de visualización & Test 8 & \ding{51} \\
OE6: Herramientas administrativas & Test 11 & \ding{51} \\
OE7: Documentar sistema & Capítulos 1-6 & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} \textbf{100\% de objetivos cumplidos} y validados.

\section{Pruebas de Rendimiento}

\subsection{Escalabilidad}

\subsubsection{Test 10: Medidores Concurrentes}

\begin{verbatim}
Descripción: Medir capacidad de gestión de medidores concurrentes
Método: Incrementar número de medidores simulados y medir latencias
Configuración: Intervalo de lectura 60s, 8 OBIS por medidor
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 10 - Escalabilidad}
\begin{tabular}{ccccc}
\toprule
\textbf{Medidores} & \textbf{CPU} & \textbf{RAM} & \textbf{Latencia P50} & \textbf{Latencia P99} \\
\midrule
10 & 8\% & 145 MB & 1.2s & 2.1s \\
25 & 18\% & 280 MB & 1.4s & 2.8s \\
50 & 32\% & 520 MB & 1.8s & 4.2s \\
100 & 58\% & 980 MB & 2.5s & 6.8s \\
150 & 79\% & 1.4 GB & 3.8s & 11.2s \\
200 & 95\% & 1.9 GB & 5.2s & 18.5s \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h]
\centering
\begin{tikzpicture}
\begin{axis}[
    xlabel={Número de Medidores},
    ylabel={Latencia P99 (s)},
    width=10cm,
    height=6cm,
    grid=major
]
\addplot coordinates {
    (10, 2.1)
    (25, 2.8)
    (50, 4.2)
    (100, 6.8)
    (150, 11.2)
    (200, 18.5)
};
\end{axis}
\end{tikzpicture}
\caption{Escalabilidad: Latencia vs Número de Medidores}
\end{figure}

\textbf{Resultado:} El sistema maneja eficientemente hasta \textbf{100 medidores} con latencias <7s. Más allá de 150 medidores, se requiere escalamiento horizontal.

\subsection{Throughput de Telemetría}

\subsubsection{Test 11: Capacidad de Ingesta}

\begin{verbatim}
Descripción: Medir throughput máximo de ThingsBoard
Método: Publicar telemetría a tasa creciente y medir límite
Configuración: Mensajes de 8 keys, QoS 1
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 11 - Throughput}
\begin{tabular}{cccc}
\toprule
\textbf{Tasa (msg/s)} & \textbf{Recibidos/s} & \textbf{Pérdida} & \textbf{Latencia P99} \\
\midrule
1,000 & 1,000 & 0\% & 45 ms \\
5,000 & 5,000 & 0\% & 120 ms \\
10,000 & 10,000 & 0\% & 280 ms \\
15,000 & 14,850 & 1\% & 650 ms \\
20,000 & 18,200 & 9\% & 1,200 ms \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Throughput sostenible de \textbf{10,000 msg/s} sin pérdidas. Configuración actual soporta ~150 medidores leyendo cada 60s (150 × 8 keys = 1,200 values/min = 20 msg/s).

\section{Pruebas de Resiliencia}

\subsection{Recuperación ante Fallos}

\subsubsection{Test 12: Desconexión de Medidor}

\begin{verbatim}
Descripción: Simular desconexión física de medidor
Escenario: Desconectar puerto serie durante lectura activa
Verificar: Detección de fallo, reintentos, recuperación automática
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 12 - Recuperación de Medidor}
\begin{tabular}{lcc}
\toprule
\textbf{Métrica} & \textbf{Valor} & \textbf{Objetivo} \\
\midrule
Tiempo de detección & 5.2s & <10s \\
Número de reintentos & 3 & 5 \\
Tiempo total recuperación & 18s & <60s \\
Lecturas perdidas & 1 & <3 \\
Estado final & Recuperado & Recuperado \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Recuperación exitosa en \textbf{18s}, dentro del objetivo.

\subsubsection{Test 13: Caída de ThingsBoard}

\begin{verbatim}
Descripción: Simular caída de plataforma ThingsBoard
Escenario: Detener contenedor ThingsBoard por 2 minutos
Verificar: Buffering local, recuperación al restaurar
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 13 - Caída de ThingsBoard}
\begin{tabular}{lcc}
\toprule
\textbf{Fase} & \textbf{Mensajes Generados} & \textbf{Estado} \\
\midrule
Pre-fallo (1 min) & 120 & Publicados \\
Durante fallo (2 min) & 240 & Buffereados \\
Post-recuperación (2 min) & 360 & Publicados \\
\midrule
\textbf{Total} & \textbf{720} & \textbf{720 recibidos} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} \textbf{0\% de pérdida} de telemetría gracias al buffer local. Todos los 240 mensajes buffereados se publicaron exitosamente tras recuperación.

\subsubsection{Test 14: Saturación de Red}

\begin{verbatim}
Descripción: Simular saturación de red con tc (traffic control)
Escenario: Limitar ancho de banda a 100 kbps durante 5 minutos
Verificar: Buffering, control de flujo, no pérdida de datos
\end{verbatim}

\begin{verbatim}
# Comando para limitar ancho de banda
$ tc qdisc add dev eth0 root tbf rate 100kbit burst 10kb latency 50ms
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 14 - Red Saturada}
\begin{tabular}{lccc}
\toprule
\textbf{Métrica} & \textbf{Normal} & \textbf{Saturada} & \textbf{Variación} \\
\midrule
Latencia P50 & 24 ms & 850 ms & +35x \\
Latencia P99 & 87 ms & 2,400 ms & +27x \\
Buffer máximo & 12 msgs & 450 msgs & +37x \\
Mensajes perdidos & 0 & 0 & - \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} El sistema manejó la saturación sin pérdida de datos, aunque con latencias elevadas. El buffer de 10,000 mensajes fue suficiente.

\subsection{Disponibilidad}

\subsubsection{Test 15: Prueba de Larga Duración}

\begin{verbatim}
Descripción: Ejecutar sistema durante 7 días continuos
Configuración: 20 medidores simulados, lectura cada 5 minutos
Verificar: Estabilidad, fugas de memoria, degradación de rendimiento
\end{verbatim}

\begin{table}[h]
\centering
\caption{Resultados Test 15 - Prueba de 7 Días}
\begin{tabular}{lcc}
\toprule
\textbf{Métrica} & \textbf{Valor} & \textbf{Estado} \\
\midrule
Lecturas totales & 40,320 & 100\% \\
Lecturas exitosas & 40,278 & 99.90\% \\
Lecturas fallidas & 42 & 0.10\% \\
Uptime orquestador & 99.95\% & \ding{51} \\
Uptime ThingsBoard & 99.98\% & \ding{51} \\
Uso de memoria máximo & 1.2 GB & Estable \\
Fugas detectadas & 0 & \ding{51} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Resultado:} Disponibilidad de \textbf{99.90\%} durante 7 días, sin fugas de memoria ni degradación de rendimiento.

\section{Análisis de Resultados}

\subsection{Cumplimiento de Objetivos}

\begin{table}[h]
\centering
\caption{Resumen de cumplimiento de objetivos}
\begin{tabular}{p{6cm}cc}
\toprule
\textbf{Objetivo} & \textbf{Objetivo} & \textbf{Logrado} \\
\midrule
Cobertura de tests & >90\% & 94\% \\
Precisión de lecturas & >99\% & 99.99\% \\
Latencia end-to-end & <5s & 1.97s \\
Medidores concurrentes & >50 & 100 \\
Throughput & >1,000 msg/s & 10,000 msg/s \\
Disponibilidad & >99\% & 99.90\% \\
Pérdida de datos & <0.1\% & 0\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Conclusión:} Todos los objetivos cuantitativos fueron \textbf{cumplidos o superados}.

\subsection{Comparación con Estado del Arte}

\begin{table}[h]
\centering
\caption{Comparación con soluciones existentes}
\begin{tabular}{lccc}
\toprule
\textbf{Característica} & \textbf{Este Proyecto} & \textbf{Gurux} & \textbf{OpenMUC} \\
\midrule
Licencia & Open Source & Comercial & Open Source \\
Plataforma IoT & ThingsBoard & No & Parcial \\
Recuperación automática & Sí & No & Limitada \\
Dashboards & Sí & No & No \\
Medidores concurrentes & 100 & 50 & 20 \\
Documentación & Completa & Comercial & Básica \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Limitaciones Identificadas}

\begin{enumerate}
    \item \textbf{Escalabilidad vertical:} Más allá de 150 medidores se requiere escalamiento horizontal
    \item \textbf{Latencias en redes saturadas:} Latencias aumentan significativamente en condiciones de red deficientes
    \item \textbf{Soporte de fabricantes:} Algunas variantes propietarias de DLMS no están completamente soportadas
    \item \textbf{Configuración inicial:} Requiere conocimiento técnico para configurar medidores nuevos
\end{enumerate}

\subsection{Ventajas Observadas}

\begin{enumerate}
    \item \textbf{Zero data loss:} 0\% de pérdida de telemetría incluso ante fallos
    \item \textbf{Auto-recovery:} Recuperación automática sin intervención humana
    \item \textbf{Bajo costo:} Solución completamente open-source
    \item \textbf{Flexibilidad:} Fácil integración con sistemas externos vía APIs
    \item \textbf{Observabilidad:} Métricas y logs completos para troubleshooting
\end{enumerate}

\section{Casos de Uso Reales}

\subsection{Caso 1: Monitoreo de Subestación}

\begin{verbatim}
Escenario: Monitoreo de 15 medidores en subestación eléctrica
Despliegue: Raspberry Pi 4 (4GB RAM) como gateway
Resultados:
- Latencia promedio: 2.3s
- Disponibilidad: 99.92% durante 30 días
- CPU promedio: 35%
- Alertas generadas: 12 (voltaje fuera de rango)
\end{verbatim}

\subsection{Caso 2: AMI Residencial}

\begin{verbatim}
Escenario: Red AMI con 50 medidores residenciales
Despliegue: PC industrial con Ubuntu 22.04
Resultados:
- Lecturas cada 15 minutos
- Throughput: 200 msg/min
- Energía total monitoreada: 45,000 kWh/mes
- Detección de anomalías: 3 casos de consumo atípico
\end{verbatim}

\section{Lecciones Aprendidas}

\subsection{Aspectos Técnicos}

\begin{enumerate}
    \item \textbf{Buffering es crítico:} El buffer local evitó pérdida de datos en todos los escenarios de fallo
    \item \textbf{Timeouts adaptativos:} Reducen falsos positivos en medidores con latencias variables
    \item \textbf{Threading vs Asyncio:} Threading resultó más estable para comunicación serie bloqueante
    \item \textbf{QoS 1 suficiente:} QoS 2 añade overhead sin beneficios significativos para telemetría
\end{enumerate}

\subsection{Aspectos Operacionales}

\begin{enumerate}
    \item \textbf{Documentación esencial:} La configuración YAML requiere documentación clara
    \item \textbf{Health checks importantes:} Facilitan detección temprana de problemas
    \item \textbf{Logs estructurados:} JSON facilita análisis automatizado de logs
    \item \textbf{Dashboards vitales:} Permiten identificar problemas visualmente
\end{enumerate}

\section{Conclusiones del Capítulo}

Las pruebas realizadas validan que el sistema SmartMeter2ThingsBoard-Gateway:

\begin{itemize}
    \item Cumple todos los objetivos específicos planteados
    \item Maneja eficientemente hasta 100 medidores concurrentes
    \item Proporciona disponibilidad >99.9\% con recuperación automática
    \item Garantiza 0\% de pérdida de telemetría mediante buffering
    \item Supera a soluciones open-source existentes en funcionalidad
    \item Es viable para despliegues reales en subestaciones y redes AMI
\end{itemize}

Las limitaciones identificadas (escalabilidad vertical, latencias en redes saturadas) son mitigables mediante escalamiento horizontal y optimización de red, respectivamente.

El siguiente capítulo presenta las conclusiones generales del proyecto y recomendaciones para trabajo futuro.
